# Project Plan: OpenAI API Router with OpenRouter Backend

**Last Updated:** 2025-05-10

**Objective:** Create an API router that emulates OpenAI API endpoints, intelligently processes requests containing image or video links, logs activity, tracks costs, and routes requests to appropriate models via OpenRouter.

## 1. Core Technology & Setup

*   **Language/Framework:** Python 3.x with FastAPI.
*   **API Key Management:** `OPENROUTER_API_KEY` will be stored in and read from a `.env` file.
*   **Configuration:** Other settings (e.g., default models, logging paths, `HTTP-Referer`, `X-Title` for OpenRouter) can also be managed via the `.env` file or a separate configuration file (e.g., `config.py`).
*   **Dependencies:**
    *   `fastapi`: For the web framework.
    *   `uvicorn[standard]`: ASGI server for FastAPI (includes `python-multipart` for form data, useful for potential file uploads if ever needed, and `websockets` if needed in future).
    *   `python-dotenv`: To load `.env` files.
    *   `requests`: For synchronous HTTP requests (can be used by `yt-dlp` or other blocking libraries).
    *   `aiohttp`: For asynchronous HTTP requests within FastAPI (e.g., to OpenRouter, downloading media).
    *   `yt-dlp`: For downloading videos from various sources.
    *   `ffmpeg-python`: For video frame extraction and audio extraction.
    *   `faster-whisper`: For audio transcription.
    *   `Pillow` or `opencv-python`: For image manipulation if needed (Pillow is lighter if only conversion/resizing is needed; OpenCV for complex ops).
    *   `SQLAlchemy` (version 2.x for async support).
    *   `aiosqlite`: Async driver for SQLite with SQLAlchemy.
    *   `pydantic`: For data validation (FastAPI uses it extensively).
    *   `Jinja2`: For HTML templating for the UI.

## 2. API Endpoints Implementation

*   **`POST /v1/chat/completions`**:
    *   Accepts OpenAI-compatible chat completion requests.
    *   Implements logic to detect image/video content (see section 6 & 7).
    *   Routes to OpenRouter.
*   **`POST /v1/completions` (Legacy)**:
    *   Accepts OpenAI-compatible legacy completion requests.
    *   Implements logic to detect image/video content.
    *   Routes to OpenRouter.
    *   Note: This endpoint typically uses a `prompt` string. If multimedia content is detected, it will need to be transformed into a `messages` structure compatible with multimodal models on OpenRouter.

## 3. Logging and Cost Tracking

*   **Request/Response Logging:**
    *   Log full request and response bodies (including relevant headers for debugging) in a structured JSON format.
    *   Logs will be written to a file named `router.json`. Implement log rotation (e.g., using Python's `logging.handlers.RotatingFileHandler`).
    *   Include timestamps (ISO 8601), a unique internal request ID, endpoint called, and processing duration.
*   **Error Logging:**
    *   Log any exceptions or errors encountered during processing, also to `router.json` with stack traces and relevant context.
*   **Database for Cost Tracking (SQLite):**
    *   **Table:** `openrouter_requests`
    *   **Schema:**
        *   `id` (Integer, Primary Key, Auto-increment)
        *   `timestamp` (DateTime, Default current_timestamp, Indexed)
        *   `internal_request_id` (String, Unique, Not Null) - Generated by the router.
        *   `endpoint_called` (String, Not Null - e.g., `/v1/chat/completions`)
        *   `client_ip` (String, Nullable)
        *   `model_requested_by_client` (String, Nullable)
        *   `model_routed_to_openrouter` (String, Not Null)
        *   `openrouter_request_id` (String, Nullable) - If OpenRouter returns one in response headers or body.
        *   `prompt_tokens` (Integer, Nullable)
        *   `completion_tokens` (Integer, Nullable)
        *   `total_tokens` (Integer, Nullable)
        *   `cost_usd` (Float, Nullable) - As reported by OpenRouter.
        *   `is_multimodal` (Boolean, Default False, Not Null)
        *   `media_type_processed` (String, Nullable - e.g., 'image', 'video', 'image_link', 'video_link')
        *   `input_char_length` (Integer, Nullable) - Length of text input.
        *   `output_char_length` (Integer, Nullable) - Length of text output.
        *   `processing_duration_ms` (Integer, Nullable) - Total time taken by the router for the request.
        *   `openrouter_latency_ms` (Integer, Nullable) - Time taken for the OpenRouter call itself.
        *   `status_code_returned_to_client` (Integer, Not Null)
        *   `error_source` (String, Nullable - e.g., 'router', 'openrouter', 'media_processing')
        *   `error_message` (Text, Nullable)
    *   **Logic:** After each call to OpenRouter, parse the response and record details. Use OpenRouter's `usage: {include: true}` parameter or the `/api/v1/generation?id=<ID>` endpoint.

## 4. Request Preprocessing & Routing Logic

*   **System Prompt Handling:**
    *   For standard requests (no video processing), pass through any `system` role messages to OpenRouter.
    *   For video processing, the original user prompt (and potentially system prompt if deemed necessary to reconstruct) will be part of the new structured input for the vision model.
*   **Default Text Model:** If no media is detected, and the client doesn't specify a model, the router will use a configurable default text model (e.g., `openai/gpt-3.5-turbo`).
*   **Vision Model (Static Images & Video):** `mistralai/mistral-small-3.1-24b-instruct` will be used.
*   **Flow Diagram (Simplified):**
    ```mermaid
    graph TD
        A[Client Request In] --> B{Detect Media Type};
        B -- Text Only --> C[Route to OpenRouter (Default/Specified Text Model)];
        B -- Image Link/Data --> D[Process Image];
        D --> E[Route to OpenRouter (Vision Model: mistralai/mistral-small-3.1-24b-instruct)];
        B -- Video Link --> F[Process Video];
        F --> E;
        C --> G[Log Request/Response/Cost DB];
        E --> G;
        G --> H[Return Response to Client];
    ```

## 5. Image Processing Module

*   **Input:** Request body (JSON).
*   **Detection:**
    *   Scan `messages` (for chat) or `prompt` (for legacy) for URLs using regex.
    *   Check if URLs end with common image extensions (`.png`, `.jpg`, `.jpeg`, `.gif`, `.webp`).
    *   Detect if any message content part is already a base64 data URL (`data:image/...;base64,...`).
*   **Handling:**
    *   If base64 image data is found, extract and use it.
    *   If image URLs are found:
        *   Asynchronously download the image using `aiohttp` to a temporary in-memory buffer or file.
        *   Convert the downloaded image to a base64 string.
    *   Modify the request payload for OpenRouter:
        *   Ensure the `model` is set to `mistralai/mistral-small-3.1-24b-instruct`.
        *   Format the `messages` array to include text parts and image parts (as base64 data URLs) according to OpenRouter's multimodal input specification.
        ```json
        // Example for OpenRouter
        {
          "model": "mistralai/mistral-small-3.1-24b-instruct",
          "messages": [
            {
              "role": "user",
              "content": [
                { "type": "text", "text": "Original prompt text." },
                { "type": "image_url", "image_url": { "url": "data:image/jpeg;base64,..." } }
              ]
            }
            // Include system prompt if present and applicable
          ]
        }
        ```

## 6. Video Processing Module

*   **Input:** Request body (JSON).
*   **Detection:**
    *   Scan `messages` or `prompt` for URLs using regex.
    *   Check if URLs end with common video extensions (e.g., `.mp4`, `.mov`, `.avi`, `.mkv`, `.webm`).
*   **Handling (Async Pipeline):**
    1.  **Download Video:** Use `yt-dlp` (run as a subprocess using `asyncio.create_subprocess_exec`) to download the video to a temporary local file. Define a timeout.
    2.  **Extract Audio:** Use `ffmpeg-python` (run via `FastAPI.run_in_threadpool` or `asyncio.to_thread` as ffmpeg calls can be blocking) to extract the audio track from the temporary video file into a temporary audio file (e.g., `.wav` or `.mp3`).
    3.  **Transcribe Audio:** Use `faster-whisper` (run via `FastAPI.run_in_threadpool` or `asyncio.to_thread`) to transcribe the temporary audio file.
    4.  **Extract Keyframes:** Use `ffmpeg-python` (run via `FastAPI.run_in_threadpool` or `asyncio.to_thread`) to extract 3 keyframes from the temporary video file. Convert these frames to base64 strings.
    5.  **Cleanup:** Ensure robust cleanup of temporary video, audio, and frame files using `try/finally` blocks or context managers.
    6.  **Prepare Request for OpenRouter:**
        *   Set `model` to `mistralai/mistral-small-3.1-24b-instruct`.
        *   Construct the `messages` payload:
            *   Create a structured text block combining the original user prompt and the generated transcript.
            *   Include the 3 base64 encoded keyframes.
            ```json
            {
              "model": "mistralai/mistral-small-3.1-24b-instruct",
              "messages": [
                {
                  "role": "user",
                  "content": [
                    { "type": "text", "text": "Original prompt: [User's original text prompt here]\n\nVideo Transcript:\n[Transcript text from faster-whisper here]" },
                    { "type": "image_url", "image_url": { "url": "data:image/jpeg;base64,[frame1_base64]" } },
                    { "type": "image_url", "image_url": { "url": "data:image/jpeg;base64,[frame2_base64]" } },
                    { "type": "image_url", "image_url": { "url": "data:image/jpeg;base64,[frame3_base64]" } }
                  ]
                }
                // Include system prompt if present and applicable
              ]
            }
            ```

## 7. OpenRouter Integration Module

*   A dedicated module/class (e.g., `openrouter_client.py`) to handle communication with `https://openrouter.ai/api/v1`.
*   Takes the prepared request payload.
*   Adds `Authorization: Bearer <OPENROUTER_API_KEY>` header.
*   Adds configurable `HTTP-Referer` and `X-Title` headers.
*   Makes the POST request using `aiohttp.ClientSession`.
*   Handles responses, including rate limits and other errors from OpenRouter.
*   Extracts usage/cost information.

## 8. Error Handling

*   Implement global error handling middleware in FastAPI to catch unhandled exceptions and return standardized OpenAI-compatible JSON error responses.
*   Specific error handling within media processing (download, ffmpeg, whisper) to log issues and potentially return informative errors to the client (e.g., "Failed to process video link").
*   Retry mechanisms (e.g., with exponential backoff) for transient network errors when calling OpenRouter could be considered for robustness.

## 9. Development & Deployment

*   **Virtual Environment:** Use `python -m venv .venv`.
*   **`requirements.txt`:** Maintain with `pip freeze > requirements.txt`.
*   **Development Server:** `uvicorn main:app --reload --host 0.0.0.0 --port 8000`.
*   **Linters/Formatters:** `black`, `ruff` (or `flake8`/`pylint`).
*   **Testing:** Consider `pytest` for unit and integration tests, especially for processing logic and OpenRouter client.
*   **Deployment:** Docker is highly recommended. The `Dockerfile` will need to:
    *   Install Python and project dependencies.
    *   Install `ffmpeg` (system dependency for `ffmpeg-python`).
    *   Copy project code.
    *   Set up the `.env` file or pass environment variables.
    *   Expose the application port.

## 10. Simple UI for Cost Tracking Database Viewing

*   **Objective:** Provide a web interface to view records from the cost tracking SQLite database.
*   **Technology:**
    *   FastAPI endpoints to serve HTML and data.
    *   Jinja2 for HTML templating.
    *   Simple HTML, CSS (e.g., Pico.css or custom), and minimal JavaScript for interactivity if needed (e.g., client-side search/sort for the displayed page).
*   **Functionality:**
    *   **Main View:** A table displaying records from the `openrouter_requests` table.
        *   Columns: `timestamp`, `endpoint_called`, `model_routed_to_openrouter`, `prompt_tokens`, `completion_tokens`, `total_tokens`, `cost_usd`, `status_code_returned_to_client`, `error_message`.
        *   Pagination for large datasets.
        *   Basic sorting by columns.
    *   **Filtering (Optional):** By date range, model name, or status.
*   **FastAPI Endpoints for UI:**
    *   `GET /ui/tracking/`: Serves the main HTML page.
    *   `GET /api/ui/tracking_data/`: API endpoint for fetching paginated/sorted/filtered tracking data as JSON.
*   **Database Access:** UI endpoints will use SQLAlchemy (async via `aiosqlite`) for read-only queries.
*   **Security:**
    *   If exposed, protect with HTTP Basic Auth or a similar simple mechanism.
    *   Consider environment variable to enable/disable UI or set auth credentials.

---
This plan should provide a solid foundation for the project.